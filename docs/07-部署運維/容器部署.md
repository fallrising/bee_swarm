# 容器部署

## 概述

本章節詳細說明 Bee Swarm 項目的容器化部署方案，包括 Docker 容器化、Docker Compose 編排、Kubernetes 部署和生產環境配置等內容。

## 目錄

- [Docker 容器化](#docker-容器化)
- [Docker Compose 編排](#docker-compose-編排)
- [Kubernetes 部署](#kubernetes-部署)
- [容器註冊表](#容器註冊表)
- [安全配置](#安全配置)
- [監控與日誌](#監控與日誌)
- [備份與恢復](#備份與恢復)
- [部署策略](#部署策略)

## Docker 容器化

### 基礎 Dockerfile

#### 生產環境 Dockerfile
```dockerfile
# docs/07-部署運維/containers/Dockerfile
FROM python:3.9-slim as base

# 設置工作目錄
WORKDIR /app

# 安裝系統依賴項
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    git \
    && rm -rf /var/lib/apt/lists/*

# 建立非 root 使用者
RUN groupadd -r appuser && useradd -r -g appuser appuser

# 複製 requirements 並安裝 Python 依賴項
COPY requirements.txt requirements-prod.txt ./
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements-prod.txt

# 複製應用程式代碼
COPY --chown=appuser:appuser . .

# 設置環境變數
ENV PYTHONPATH=/app
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1

# 切換到非 root 使用者
USER appuser

# 健康檢查
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# 暴露端口
EXPOSE 8000

# 啟動命令
CMD ["gunicorn", "main:app", "--bind", "0.0.0.0:8000", "--worker-class", "uvicorn.workers.UvicornWorker", "--workers", "4"]
```

#### 多階段構建 Dockerfile
```dockerfile
# 多階段構建範例
FROM python:3.9-slim as builder

WORKDIR /app

# 安裝構建依賴項
RUN apt-get update && apt-get install -y \
    build-essential \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# 安裝 Python 依賴項
COPY requirements.txt .
RUN pip install --user --no-cache-dir -r requirements.txt

# 生產階段
FROM python:3.9-slim as production

WORKDIR /app

# 從 builder 階段複製已安裝的套件
COPY --from=builder /root/.local /root/.local

# 安裝運行時依賴項
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*

# 建立使用者
RUN groupadd -r appuser && useradd -r -g appuser appuser

# 複製應用程式
COPY --chown=appuser:appuser . .

# 設置 PATH
ENV PATH=/root/.local/bin:$PATH
ENV PYTHONPATH=/app

USER appuser

HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

EXPOSE 8000

CMD ["gunicorn", "main:app", "--bind", "0.0.0.0:8000", "--worker-class", "uvicorn.workers.UvicornWorker"]
```

### 特殊用途 Dockerfile

#### 模擬器專用容器
```dockerfile
# Dockerfile.simulator
FROM python:3.9-slim

WORKDIR /app

# 安裝科學計算依賴項
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    gfortran \
    libopenblas-dev \
    liblapack-dev \
    && rm -rf /var/lib/apt/lists/*

# 安裝 Python 科學計算套件
COPY requirements-simulator.txt .
RUN pip install --no-cache-dir -r requirements-simulator.txt

# 複製模擬器代碼
COPY simulator/ ./simulator/
COPY scripts/ ./scripts/

# 設置環境變數
ENV PYTHONPATH=/app
ENV SIMULATION_WORKERS=4
ENV SIMULATION_TIMEOUT=3600

# 建立結果目錄
RUN mkdir -p /app/results && \
    groupadd -r simuser && \
    useradd -r -g simuser simuser && \
    chown -R simuser:simuser /app

USER simuser

# 模擬器健康檢查
HEALTHCHECK --interval=60s --timeout=30s --start-period=10s --retries=3 \
    CMD python -c "import simulator; print('OK')" || exit 1

CMD ["python", "-m", "simulator.main"]
```

#### 工作佇列容器
```dockerfile
# Dockerfile.worker
FROM python:3.9-slim

WORKDIR /app

# 安裝依賴項
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*

COPY requirements-worker.txt .
RUN pip install --no-cache-dir -r requirements-worker.txt

# 複製工作者代碼
COPY worker/ ./worker/
COPY shared/ ./shared/

ENV PYTHONPATH=/app
ENV CELERY_BROKER_URL=redis://redis:6379/0
ENV CELERY_RESULT_BACKEND=redis://redis:6379/0

RUN groupadd -r worker && useradd -r -g worker worker
USER worker

HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD celery -A worker.celery inspect ping || exit 1

CMD ["celery", "-A", "worker.celery", "worker", "--loglevel=info"]
```

## Docker Compose 編排

### 開發環境配置

#### docker-compose.dev.yml
```yaml
version: '3.8'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile.dev
    ports:
      - "8000:8000"
    volumes:
      - .:/app
      - /app/__pycache__
    environment:
      - ENVIRONMENT=development
      - DEBUG=true
      - DATABASE_URL=postgresql://dev_user:dev_pass@postgres:5432/bee_swarm_dev
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - bee-swarm-network

  postgres:
    image: postgres:13-alpine
    environment:
      POSTGRES_DB: bee_swarm_dev
      POSTGRES_USER: dev_user
      POSTGRES_PASSWORD: dev_pass
    ports:
      - "5432:5432"
    volumes:
      - postgres_dev_data:/var/lib/postgresql/data
      - ./scripts/init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U dev_user -d bee_swarm_dev"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - bee-swarm-network

  redis:
    image: redis:6-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_dev_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - bee-swarm-network

  simulator:
    build:
      context: .
      dockerfile: Dockerfile.simulator
    volumes:
      - ./simulation_results:/app/results
    environment:
      - SIMULATION_WORKERS=2
      - SIMULATION_TIMEOUT=1800
    depends_on:
      - redis
    networks:
      - bee-swarm-network

networks:
  bee-swarm-network:
    driver: bridge

volumes:
  postgres_dev_data:
  redis_dev_data:
```

### 生產環境配置

#### docker-compose.prod.yml
```yaml
version: '3.8'

services:
  app:
    image: bee-swarm:latest
    deploy:
      replicas: 3
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
        monitor: 60s
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    ports:
      - "8000:8000"
    environment:
      - ENVIRONMENT=production
      - DEBUG=false
      - DATABASE_URL=postgresql://prod_user:${DB_PASSWORD}@postgres:5432/bee_swarm_prod
      - REDIS_URL=redis://redis:6379/0
      - SECRET_KEY=${SECRET_KEY}
    secrets:
      - db_password
      - secret_key
    depends_on:
      - postgres
      - redis
    networks:
      - bee-swarm-backend
      - bee-swarm-frontend
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - nginx_logs:/var/log/nginx
    depends_on:
      - app
    networks:
      - bee-swarm-frontend
    deploy:
      replicas: 2
      restart_policy:
        condition: on-failure

  postgres:
    image: postgres:13-alpine
    environment:
      POSTGRES_DB: bee_swarm_prod
      POSTGRES_USER: prod_user
      POSTGRES_PASSWORD_FILE: /run/secrets/db_password
    volumes:
      - postgres_prod_data:/var/lib/postgresql/data
      - ./backup:/backup
    secrets:
      - db_password
    networks:
      - bee-swarm-backend
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.role == manager

  redis:
    image: redis:6-alpine
    volumes:
      - redis_prod_data:/data
      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf
    command: redis-server /usr/local/etc/redis/redis.conf
    networks:
      - bee-swarm-backend
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure

  worker:
    image: bee-swarm-worker:latest
    deploy:
      replicas: 2
      restart_policy:
        condition: on-failure
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    depends_on:
      - redis
    networks:
      - bee-swarm-backend

  beat:
    image: bee-swarm-worker:latest
    command: celery -A worker.celery beat --loglevel=info
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    depends_on:
      - redis
    networks:
      - bee-swarm-backend

networks:
  bee-swarm-frontend:
    driver: overlay
    external: true
  bee-swarm-backend:
    driver: overlay
    external: true

volumes:
  postgres_prod_data:
    driver: local
  redis_prod_data:
    driver: local
  nginx_logs:
    driver: local

secrets:
  db_password:
    external: true
  secret_key:
    external: true
```

## Kubernetes 部署

### 基礎配置

#### Namespace
```yaml
# k8s/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: bee-swarm
  labels:
    name: bee-swarm
    environment: production
```

#### ConfigMap
```yaml
# k8s/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: bee-swarm-config
  namespace: bee-swarm
data:
  ENVIRONMENT: "production"
  DEBUG: "false"
  LOG_LEVEL: "INFO"
  SIMULATION_WORKERS: "4"
  SIMULATION_TIMEOUT: "3600"
  ALLOWED_HOSTS: "api.yourdomain.com"
  CORS_ORIGINS: "https://yourdomain.com"
```

#### Secret
```yaml
# k8s/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: bee-swarm-secrets
  namespace: bee-swarm
type: Opaque
data:
  DATABASE_URL: cG9zdGdyZXNxbDovL3Byb2RfdXNlcjpzdHJvbmdfcGFzc3dvcmRAcG9zdGdyZXM6NTQzMi9iZWVfc3dhcm1fcHJvZA==
  REDIS_URL: cmVkaXM6Ly9yZWRpczozNzkg
  SECRET_KEY: eW91ci1zdXBlci1zZWNyZXQta2V5LWhlcmU=
  GITHUB_TOKEN: Z2hwXzEyMzQ1Njc4OTA=
```

### 應用部署

#### API 服務部署
```yaml
# k8s/api-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: bee-swarm-api
  namespace: bee-swarm
  labels:
    app: bee-swarm-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: bee-swarm-api
  template:
    metadata:
      labels:
        app: bee-swarm-api
    spec:
      containers:
      - name: api
        image: bee-swarm:latest
        ports:
        - containerPort: 8000
        env:
        - name: ENVIRONMENT
          valueFrom:
            configMapKeyRef:
              name: bee-swarm-config
              key: ENVIRONMENT
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: bee-swarm-secrets
              key: DATABASE_URL
        - name: REDIS_URL
          valueFrom:
            secretKeyRef:
              name: bee-swarm-secrets
              key: REDIS_URL
        - name: SECRET_KEY
          valueFrom:
            secretKeyRef:
              name: bee-swarm-secrets
              key: SECRET_KEY
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
        volumeMounts:
        - name: logs
          mountPath: /app/logs
      volumes:
      - name: logs
        emptyDir: {}
      imagePullPolicy: Always
      restartPolicy: Always

---
apiVersion: v1
kind: Service
metadata:
  name: bee-swarm-api-service
  namespace: bee-swarm
spec:
  selector:
    app: bee-swarm-api
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: ClusterIP
```

#### 模擬器部署
```yaml
# k8s/simulator-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: bee-swarm-simulator
  namespace: bee-swarm
spec:
  replicas: 2
  selector:
    matchLabels:
      app: bee-swarm-simulator
  template:
    metadata:
      labels:
        app: bee-swarm-simulator
    spec:
      containers:
      - name: simulator
        image: bee-swarm-simulator:latest
        envFrom:
        - configMapRef:
            name: bee-swarm-config
        - secretRef:
            name: bee-swarm-secrets
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        volumeMounts:
        - name: simulation-results
          mountPath: /app/results
      volumes:
      - name: simulation-results
        persistentVolumeClaim:
          claimName: simulation-results-pvc

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: simulation-results-pvc
  namespace: bee-swarm
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 10Gi
  storageClassName: nfs-storage
```

#### 資料庫部署
```yaml
# k8s/postgres-deployment.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
  namespace: bee-swarm
spec:
  serviceName: "postgres"
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:13-alpine
        ports:
        - containerPort: 5432
        env:
        - name: POSTGRES_DB
          value: "bee_swarm_prod"
        - name: POSTGRES_USER
          value: "prod_user"
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: password
        volumeMounts:
        - name: postgres-storage
          mountPath: /var/lib/postgresql/data
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        livenessProbe:
          exec:
            command:
            - pg_isready
            - -U
            - prod_user
            - -d
            - bee_swarm_prod
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          exec:
            command:
            - pg_isready
            - -U
            - prod_user
            - -d
            - bee_swarm_prod
          initialDelaySeconds: 5
          periodSeconds: 5
  volumeClaimTemplates:
  - metadata:
      name: postgres-storage
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: "ssd-storage"
      resources:
        requests:
          storage: 20Gi

---
apiVersion: v1
kind: Service
metadata:
  name: postgres
  namespace: bee-swarm
spec:
  selector:
    app: postgres
  ports:
  - port: 5432
  clusterIP: None
```

### Ingress 配置

#### HTTPS Ingress
```yaml
# k8s/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: bee-swarm-ingress
  namespace: bee-swarm
  annotations:
    kubernetes.io/ingress.class: "nginx"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/rate-limit: "100"
    nginx.ingress.kubernetes.io/rate-limit-window: "1m"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
spec:
  tls:
  - hosts:
    - api.yourdomain.com
    secretName: bee-swarm-tls
  rules:
  - host: api.yourdomain.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: bee-swarm-api-service
            port:
              number: 80
```

### 自動擴展配置

#### HPA (Horizontal Pod Autoscaler)
```yaml
# k8s/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: bee-swarm-api-hpa
  namespace: bee-swarm
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: bee-swarm-api
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15
      - type: Pods
        value: 2
        periodSeconds: 60
```

## 容器註冊表

### Docker Hub 配置

#### 構建並推送腳本
```bash
#!/bin/bash
# scripts/docker-build-push.sh

set -e

# 配置變數
REGISTRY="your-dockerhub-username"
IMAGE_NAME="bee-swarm"
VERSION=${1:-latest}

# 構建映像
echo "Building Docker images..."

# API 映像
docker build -t ${REGISTRY}/${IMAGE_NAME}:${VERSION} .
docker build -t ${REGISTRY}/${IMAGE_NAME}:latest .

# 模擬器映像
docker build -f Dockerfile.simulator -t ${REGISTRY}/${IMAGE_NAME}-simulator:${VERSION} .
docker build -f Dockerfile.simulator -t ${REGISTRY}/${IMAGE_NAME}-simulator:latest .

# 工作者映像
docker build -f Dockerfile.worker -t ${REGISTRY}/${IMAGE_NAME}-worker:${VERSION} .
docker build -f Dockerfile.worker -t ${REGISTRY}/${IMAGE_NAME}-worker:latest .

# 登入 Docker Hub
echo "Logging in to Docker Hub..."
echo ${DOCKER_PASSWORD} | docker login -u ${DOCKER_USERNAME} --password-stdin

# 推送映像
echo "Pushing images to Docker Hub..."
docker push ${REGISTRY}/${IMAGE_NAME}:${VERSION}
docker push ${REGISTRY}/${IMAGE_NAME}:latest
docker push ${REGISTRY}/${IMAGE_NAME}-simulator:${VERSION}
docker push ${REGISTRY}/${IMAGE_NAME}-simulator:latest
docker push ${REGISTRY}/${IMAGE_NAME}-worker:${VERSION}
docker push ${REGISTRY}/${IMAGE_NAME}-worker:latest

echo "Build and push completed successfully!"
```

### 私有註冊表配置

#### Harbor 私有註冊表
```yaml
# harbor/docker-compose.yml
version: '2.3'

services:
  registry:
    image: goharbor/harbor-registryctl:v2.5.0
    container_name: registryctl
    env_file:
      - ./harbor.env
    restart: always
    volumes:
      - /data/registry:/storage
      - ./config/registry/:/etc/registry/
      - type: bind
        source: ./config/registryctl/config.yml
        target: /etc/registryctl/config.yml
    networks:
      - harbor
    depends_on:
      - log
    logging:
      driver: "syslog"
      options:
        syslog-address: "tcp://localhost:1514"
        tag: "registryctl"

  core:
    image: goharbor/harbor-core:v2.5.0
    container_name: harbor-core
    env_file:
      - ./harbor.env
    restart: always
    volumes:
      - /data/ca_download/:/etc/core/ca/
      - /data/psc/:/etc/core/token/
      - /data/:/data/
      - ./config/core/app.conf:/etc/core/app.conf
    networks:
      - harbor
    ports:
      - 8080:8080
    depends_on:
      - log
      - registry
      - redis
      - postgresql
    logging:
      driver: "syslog"
      options:
        syslog-address: "tcp://localhost:1514"
        tag: "core"
```

## 安全配置

### 容器安全最佳實踐

#### 安全 Dockerfile
```dockerfile
FROM python:3.9-slim

# 更新並清理套件
RUN apt-get update && \
    apt-get upgrade -y && \
    apt-get install -y --no-install-recommends \
        curl \
        ca-certificates && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# 建立非 root 使用者
RUN groupadd -r appuser && \
    useradd -r -g appuser -d /app -s /sbin/nologin \
    -c "Docker image user" appuser

WORKDIR /app

# 設置檔案權限
COPY --chown=appuser:appuser requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY --chown=appuser:appuser . .

# 設置只讀根檔案系統
RUN chown -R appuser:appuser /app

# 切換到非 root 使用者
USER appuser

# 健康檢查
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

EXPOSE 8000

CMD ["gunicorn", "--bind", "0.0.0.0:8000", "main:app"]
```

#### 安全掃描配置
```yaml
# .github/workflows/security-scan.yml
name: Security Scan

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  security-scan:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Build Docker image
      run: docker build -t bee-swarm:scan .
    
    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: 'bee-swarm:scan'
        format: 'sarif'
        output: 'trivy-results.sarif'
    
    - name: Upload Trivy scan results to GitHub Security tab
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: 'trivy-results.sarif'
```

### 網路安全配置

#### Network Policies
```yaml
# k8s/network-policy.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: bee-swarm-network-policy
  namespace: bee-swarm
spec:
  podSelector:
    matchLabels:
      app: bee-swarm-api
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: ingress-nginx
    ports:
    - protocol: TCP
      port: 8000
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: postgres
    ports:
    - protocol: TCP
      port: 5432
  - to:
    - podSelector:
        matchLabels:
          app: redis
    ports:
    - protocol: TCP
      port: 6379
  - to: []
    ports:
    - protocol: TCP
      port: 443  # HTTPS
    - protocol: TCP
      port: 53   # DNS
    - protocol: UDP
      port: 53   # DNS
```

## 監控與日誌

### Prometheus 監控

#### ServiceMonitor
```yaml
# k8s/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: bee-swarm-metrics
  namespace: bee-swarm
  labels:
    app: bee-swarm-api
spec:
  selector:
    matchLabels:
      app: bee-swarm-api
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
```

#### 應用指標配置
```python
# metrics.py
from prometheus_client import Counter, Histogram, Gauge, generate_latest

REQUEST_COUNT = Counter('app_requests_total', 'Total requests', ['method', 'endpoint'])
REQUEST_LATENCY = Histogram('app_request_duration_seconds', 'Request latency')
ACTIVE_SIMULATIONS = Gauge('app_active_simulations', 'Number of active simulations')

def metrics_endpoint():
    return generate_latest()
```

### 日誌聚合

#### Fluentd 配置
```xml
<!-- fluentd/fluent.conf -->
<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

<filter kubernetes.**>
  @type kubernetes_metadata
</filter>

<match kubernetes.var.log.containers.**bee-swarm**.log>
  @type elasticsearch
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix bee-swarm
  include_tag_key true
  tag_key @log_name
</match>

<match **>
  @type stdout
</match>
```

#### ELK Stack 部署
```yaml
# k8s/elk-stack.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: elasticsearch
  namespace: logging
spec:
  replicas: 1
  selector:
    matchLabels:
      app: elasticsearch
  template:
    metadata:
      labels:
        app: elasticsearch
    spec:
      containers:
      - name: elasticsearch
        image: elasticsearch:7.14.0
        ports:
        - containerPort: 9200
        env:
        - name: discovery.type
          value: single-node
        - name: ES_JAVA_OPTS
          value: "-Xms512m -Xmx512m"
        volumeMounts:
        - name: es-data
          mountPath: /usr/share/elasticsearch/data
      volumes:
      - name: es-data
        persistentVolumeClaim:
          claimName: elasticsearch-pvc

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kibana
  namespace: logging
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kibana
  template:
    metadata:
      labels:
        app: kibana
    spec:
      containers:
      - name: kibana
        image: kibana:7.14.0
        ports:
        - containerPort: 5601
        env:
        - name: ELASTICSEARCH_HOSTS
          value: http://elasticsearch:9200
```

## 備份與恢復

### 資料備份策略

#### PostgreSQL 備份腳本
```bash
#!/bin/bash
# scripts/backup-postgres.sh

set -e

# 配置
NAMESPACE="bee-swarm"
POD_NAME=$(kubectl get pods -n $NAMESPACE -l app=postgres -o jsonpath='{.items[0].metadata.name}')
BACKUP_DIR="/backup/postgres/$(date +%Y%m%d_%H%M%S)"

# 建立備份目錄
mkdir -p $BACKUP_DIR

# 執行備份
echo "Starting PostgreSQL backup..."
kubectl exec -n $NAMESPACE $POD_NAME -- pg_dump -U prod_user bee_swarm_prod > $BACKUP_DIR/bee_swarm_backup.sql

# 壓縮備份
gzip $BACKUP_DIR/bee_swarm_backup.sql

# 上傳到雲端儲存 (AWS S3 範例)
aws s3 cp $BACKUP_DIR/bee_swarm_backup.sql.gz s3://bee-swarm-backups/postgres/

echo "Backup completed: $BACKUP_DIR/bee_swarm_backup.sql.gz"

# 清理舊備份 (保留 7 天)
find /backup/postgres -name "*.gz" -mtime +7 -delete
```

#### 容器映像備份
```bash
#!/bin/bash
# scripts/backup-images.sh

# 映像列表
IMAGES=(
    "bee-swarm:latest"
    "bee-swarm-simulator:latest" 
    "bee-swarm-worker:latest"
)

# 備份目錄
BACKUP_DIR="/backup/images/$(date +%Y%m%d)"
mkdir -p $BACKUP_DIR

# 備份每個映像
for image in "${IMAGES[@]}"; do
    echo "Backing up $image..."
    docker save $image | gzip > $BACKUP_DIR/${image//\//_}.tar.gz
done

echo "Image backup completed in $BACKUP_DIR"
```

### 災難恢復

#### 恢復計劃
```yaml
# disaster-recovery-plan.yml
recovery_procedures:
  database_failure:
    steps:
      - name: "識別失敗"
        action: "檢查 PostgreSQL pod 狀態"
        command: "kubectl get pods -n bee-swarm -l app=postgres"
      
      - name: "恢復資料"
        action: "從最新備份恢復"
        command: "kubectl exec postgres-pod -- psql -U prod_user -d bee_swarm_prod < backup.sql"
      
      - name: "驗證恢復"
        action: "檢查資料完整性"
        command: "kubectl exec postgres-pod -- psql -U prod_user -d bee_swarm_prod -c 'SELECT COUNT(*) FROM tasks;'"

  application_failure:
    steps:
      - name: "回滾部署"
        action: "恢復到上一個版本"
        command: "kubectl rollout undo deployment/bee-swarm-api -n bee-swarm"
      
      - name: "檢查服務狀態"
        action: "驗證應用程式運行"
        command: "kubectl get pods -n bee-swarm -l app=bee-swarm-api"

  cluster_failure:
    steps:
      - name: "建立新叢集"
        action: "使用 IaC 重建"
        command: "terraform apply -var-file=production.tfvars"
      
      - name: "恢復應用程式"
        action: "部署應用程式"
        command: "kubectl apply -f k8s/"
      
      - name: "恢復資料"
        action: "從備份恢復"
        command: "./scripts/restore-from-backup.sh"
```

## 部署策略

### 滾動更新

#### 零停機部署配置
```yaml
# k8s/rolling-update.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: bee-swarm-api
spec:
  replicas: 4
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  template:
    spec:
      containers:
      - name: api
        image: bee-swarm:latest
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
```

### 藍綠部署

#### 藍綠部署腳本
```bash
#!/bin/bash
# scripts/blue-green-deploy.sh

set -e

NAMESPACE="bee-swarm"
NEW_VERSION=$1
CURRENT_COLOR=$(kubectl get service bee-swarm-api-service -n $NAMESPACE -o jsonpath='{.spec.selector.color}')

if [ "$CURRENT_COLOR" = "blue" ]; then
    NEW_COLOR="green"
else
    NEW_COLOR="blue"
fi

echo "Current color: $CURRENT_COLOR"
echo "Deploying to: $NEW_COLOR"

# 部署新版本
kubectl set image deployment/bee-swarm-api-$NEW_COLOR -n $NAMESPACE api=bee-swarm:$NEW_VERSION

# 等待部署完成
kubectl rollout status deployment/bee-swarm-api-$NEW_COLOR -n $NAMESPACE

# 執行健康檢查
echo "Running health checks..."
kubectl run health-check --rm -i --tty --image=curlimages/curl --restart=Never -- \
  curl -f http://bee-swarm-api-$NEW_COLOR:8000/health

# 切換流量
kubectl patch service bee-swarm-api-service -n $NAMESPACE -p '{"spec":{"selector":{"color":"'$NEW_COLOR'"}}}'

echo "Deployment completed. Traffic switched to $NEW_COLOR"
```

### 金絲雀部署

#### Istio 金絲雀配置
```yaml
# istio/canary-deployment.yaml
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: bee-swarm-api
  namespace: bee-swarm
spec:
  http:
  - match:
    - headers:
        canary:
          exact: "true"
    route:
    - destination:
        host: bee-swarm-api-service
        subset: canary
  - route:
    - destination:
        host: bee-swarm-api-service
        subset: stable
      weight: 90
    - destination:
        host: bee-swarm-api-service
        subset: canary
      weight: 10

---
apiVersion: networking.istio.io/v1alpha3
kind: DestinationRule
metadata:
  name: bee-swarm-api
  namespace: bee-swarm
spec:
  host: bee-swarm-api-service
  subsets:
  - name: stable
    labels:
      version: stable
  - name: canary
    labels:
      version: canary
```

## 總結

容器部署為 Bee Swarm 項目提供了一致、可擴展和可維護的部署解決方案。通過適當的容器化策略、編排工具和部署流程，可以確保系統的高可用性和可靠性。

主要優勢：
- **環境一致性**: 開發、測試和生產環境保持一致
- **可擴展性**: 根據負載自動調整資源
- **可維護性**: 簡化部署和更新流程
- **可觀察性**: 全面的監控和日誌記錄
- **安全性**: 多層次的安全配置和最佳實踐

---

*本文檔會隨著容器技術和項目需求的發展持續更新。* 