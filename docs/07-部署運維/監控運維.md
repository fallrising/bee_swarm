# 監控運維

## 概述

本章節說明 Bee Swarm 項目的監控運維體系，包括系統監控、日誌管理、告警機制和維護流程。

## 目錄

- [監控架構](#監控架構)
- [指標收集](#指標收集)
- [日誌管理](#日誌管理)
- [告警系統](#告警系統)
- [健康檢查](#健康檢查)
- [自動化運維](#自動化運維)

## 監控架構

### 核心組件
- **Prometheus**: 指標收集和時間序列資料庫
- **Grafana**: 資料可視化和儀表板
- **Fluentd**: 日誌收集和轉發
- **Elasticsearch**: 日誌搜尋和分析
- **AlertManager**: 告警管理

### Docker Compose 配置
```yaml
# monitoring/docker-compose.yml
version: '3.8'

services:
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=15d'

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123

volumes:
  prometheus_data:
  grafana_data:
```

## 指標收集

### Prometheus 配置
```yaml
# prometheus/prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'bee-swarm-api'
    static_configs:
      - targets: ['bee-swarm-api:8000']
    metrics_path: '/metrics'

  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']
```

### 應用指標
```python
# app/metrics.py
from prometheus_client import Counter, Histogram, Gauge

REQUEST_COUNT = Counter('http_requests_total', 'Total requests', ['method', 'endpoint'])
REQUEST_DURATION = Histogram('http_request_duration_seconds', 'Request duration')
ACTIVE_SIMULATIONS = Gauge('bee_swarm_active_simulations', 'Active simulations')

@app.get("/metrics")
async def metrics():
    return Response(generate_latest(), media_type="text/plain")
```

## 日誌管理

### 結構化日誌
```python
# app/logging_config.py
import logging
import json

class JSONFormatter(logging.Formatter):
    def format(self, record):
        log_entry = {
            "timestamp": record.created,
            "level": record.levelname,
            "message": record.getMessage(),
            "module": record.module
        }
        return json.dumps(log_entry)

# 使用
logger = logging.getLogger(__name__)
handler = logging.StreamHandler()
handler.setFormatter(JSONFormatter())
logger.addHandler(handler)
```

### Fluentd 配置
```xml
<!-- fluentd/fluent.conf -->
<source>
  @type forward
  port 24224
</source>

<match bee-swarm.**>
  @type elasticsearch
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix bee-swarm
</match>
```

## 告警系統

### 告警規則
```yaml
# prometheus/rules/alerts.yml
groups:
- name: bee-swarm
  rules:
  - alert: HighErrorRate
    expr: rate(http_requests_total{status_code=~"5.."}[5m]) > 0.05
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "High error rate detected"

  - alert: ServiceDown
    expr: up{job="bee-swarm-api"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Service is down"
```

### AlertManager 配置
```yaml
# alertmanager/alertmanager.yml
global:
  slack_api_url: 'YOUR_SLACK_WEBHOOK_URL'

route:
  group_by: ['alertname']
  receiver: 'slack-notifications'

receivers:
- name: 'slack-notifications'
  slack_configs:
  - channel: '#alerts'
    title: 'Bee Swarm Alert'
    text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
```

## 健康檢查

### 健康檢查端點
```python
# app/health.py
from fastapi import APIRouter, HTTPException

router = APIRouter()

@router.get("/health")
async def health_check():
    return {"status": "healthy", "timestamp": time.time()}

@router.get("/ready")
async def readiness_check():
    # 檢查依賴服務
    try:
        # 檢查資料庫
        db.execute("SELECT 1")
        # 檢查 Redis
        redis.ping()
        return {"status": "ready"}
    except Exception as e:
        raise HTTPException(status_code=503, detail="Service not ready")
```

### Kubernetes 健康檢查
```yaml
# k8s/deployment.yaml
spec:
  template:
    spec:
      containers:
      - name: api
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
```

## 自動化運維

### 備份腳本
```bash
#!/bin/bash
# scripts/backup.sh

BACKUP_DIR="/backup/$(date +%Y%m%d_%H%M%S)"
mkdir -p $BACKUP_DIR

# PostgreSQL 備份
docker exec postgres pg_dump -U prod_user bee_swarm_prod | gzip > $BACKUP_DIR/database.sql.gz

# 上傳到雲端儲存
aws s3 cp $BACKUP_DIR/database.sql.gz s3://bee-swarm-backups/

echo "Backup completed: $BACKUP_DIR"
```

### 維護腳本
```bash
#!/bin/bash
# scripts/maintenance.sh

# 清理日誌
find /var/log/bee-swarm -name "*.log" -mtime +30 -delete

# 資料庫優化
docker exec postgres psql -U prod_user -d bee_swarm_prod -c "VACUUM ANALYZE;"

# Docker 清理
docker system prune -f

echo "Maintenance completed"
```

### Cron 排程
```bash
# /etc/crontab

# 每日備份
0 2 * * * root /opt/bee-swarm/scripts/backup.sh

# 每週維護
0 3 * * 0 root /opt/bee-swarm/scripts/maintenance.sh
```

## 故障處理

### 故障響應流程
1. **告警接收**: 透過 Slack/Email 接收告警
2. **問題診斷**: 查看監控指標和日誌
3. **緊急處理**: 重啟服務、回滾部署
4. **根本分析**: 分析根本原因
5. **預防措施**: 更新監控和部署流程

### 自動恢復腳本
```bash
#!/bin/bash
# scripts/auto-recovery.sh

check_service() {
    if ! curl -f http://localhost:8000/health > /dev/null 2>&1; then
        echo "Service down, restarting..."
        docker-compose restart bee-swarm-api
        sleep 30
        
        if curl -f http://localhost:8000/health > /dev/null 2>&1; then
            echo "Service recovered"
        else
            echo "Failed to recover service"
            # 發送緊急告警
        fi
    fi
}

# 每分鐘檢查一次
while true; do
    check_service
    sleep 60
done
```

## 最佳實踐

### 監控策略
- **分層監控**: 基礎設施 → 應用程式 → 業務指標
- **告警分級**: 嚴重程度分類處理
- **儀表板設計**: 關鍵指標一目了然
- **日誌標準化**: 結構化日誌便於分析

### 運維流程
- **自動化優先**: 減少人工操作
- **文檔記錄**: 詳細的操作手冊
- **定期演練**: 故障恢復演練
- **持續改進**: 基於監控資料優化

---

*本文檔提供監控運維的核心配置和流程指南。* 