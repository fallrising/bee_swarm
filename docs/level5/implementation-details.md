# Level 5: å®ç°ç»†èŠ‚

## ä¸šåŠ¡é¢ï¼šå…·ä½“æ“ä½œæ­¥éª¤

### 5.1 é¡¹ç›®å¯åŠ¨æµç¨‹

#### ç¯å¢ƒå‡†å¤‡
1. **ç³»ç»Ÿè¦æ±‚æ£€æŸ¥**
   ```bash
   # æ£€æŸ¥Dockerç‰ˆæœ¬
   docker --version
   # æ£€æŸ¥Docker Composeç‰ˆæœ¬
   docker-compose --version
   # æ£€æŸ¥å¯ç”¨å†…å­˜
   free -h
   # æ£€æŸ¥ç£ç›˜ç©ºé—´
   df -h
   ```

2. **ç½‘ç»œé…ç½®**
   ```bash
   # æ£€æŸ¥ç½‘ç»œè¿æ¥
   ping github.com
   # æ£€æŸ¥DNSè§£æ
   nslookup api.github.com
   # æ£€æŸ¥é˜²ç«å¢™è®¾ç½®
   sudo ufw status
   ```

3. **æƒé™è®¾ç½®**
   ```bash
   # åˆ›å»ºé¡¹ç›®ç›®å½•
   mkdir -p /opt/bee-swarm
   cd /opt/bee-swarm
   
   # è®¾ç½®ç›®å½•æƒé™
   sudo chown -R $USER:$USER /opt/bee-swarm
   chmod 755 /opt/bee-swarm
   ```

#### é…ç½®æ–‡ä»¶è®¾ç½®
1. **ç¯å¢ƒå˜é‡é…ç½®**
   ```bash
   # å¤åˆ¶ç¯å¢ƒå˜é‡æ¨¡æ¿
   cp .env.example .env
   
   # ç¼–è¾‘ç¯å¢ƒå˜é‡
   nano .env
   ```

   ```env
   # GitHubé…ç½®
   GITHUB_TOKEN_PM=ghp_xxxxxxxxxxxxxxxxxxxx
   GITHUB_TOKEN_BACKEND=ghp_xxxxxxxxxxxxxxxxxxxx
   GITHUB_TOKEN_FRONTEND=ghp_xxxxxxxxxxxxxxxxxxxx
   GITHUB_TOKEN_QA=ghp_xxxxxxxxxxxxxxxxxxxx
   GITHUB_TOKEN_DEVOPS=ghp_xxxxxxxxxxxxxxxxxxxx
   
   # AIå·¥å…·é…ç½®
   OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxx
   ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxx
   GEMINI_API_KEY=xxxxxxxxxxxxxxxxxxxx
   
   # å®¹å™¨é…ç½®
   VNC_PASSWORD_PM=vnc123
   VNC_PASSWORD_BACKEND=vnc123
   VNC_PASSWORD_FRONTEND=vnc123
   VNC_PASSWORD_QA=vnc123
   VNC_PASSWORD_DEVOPS=vnc123
   
   # Cloudflareé…ç½®
   CLOUDFLARE_TUNNEL_URL=https://your-tunnel-url.trycloudflare.com
   
   # æ•°æ®åº“é…ç½®
   REDIS_URL=redis://localhost:6379
   POSTGRES_URL=postgresql://user:password@localhost:5432/beeswarm
   ```

2. **GitHub Webhooké…ç½®**
   ```bash
   # åœ¨GitHubä»“åº“è®¾ç½®ä¸­æ·»åŠ Webhook
   # URL: https://your-domain.com/webhook
   # Content type: application/json
   # Secret: your-webhook-secret
   # Events: Issues, Pull requests, Push
   ```

#### å®¹å™¨æ„å»ºå’Œå¯åŠ¨
1. **æ„å»ºåŸºç¡€é•œåƒ**
   ```bash
   # æ„å»ºVNCåŸºç¡€é•œåƒ
   cd novnc_base
   docker build -t vnc-base .
   
   # æ„å»ºAIå·¥å…·é•œåƒ
   cd ../novnc_llm_cli
   docker build -t vnc-llm-cli .
   ```

2. **æ„å»ºè§’è‰²é•œåƒ**
   ```bash
   # æ„å»ºæ‰€æœ‰è§’è‰²é•œåƒ
   docker-compose build
   
   # æˆ–è€…æ„å»ºç‰¹å®šè§’è‰²
   docker-compose build product-manager
   docker-compose build backend-developer
   ```

3. **å¯åŠ¨æœåŠ¡**
   ```bash
   # å¯åŠ¨æ‰€æœ‰æœåŠ¡
   docker-compose up -d
   
   # å¯åŠ¨ç‰¹å®šæœåŠ¡
   docker-compose up -d product-manager
   
   # æŸ¥çœ‹æœåŠ¡çŠ¶æ€
   docker-compose ps
   ```

### 5.2 è§’è‰²å·¥ä½œæµç¨‹

#### äº§å“ç»ç†å·¥ä½œæµç¨‹
1. **éœ€æ±‚æ¥æ”¶å’Œåˆ†æ**
   ```bash
   # è¿›å…¥äº§å“ç»ç†å®¹å™¨
   docker exec -it bee-swarm-product-manager-1 bash
   
   # å¯åŠ¨äº§å“ç»ç†æœåŠ¡
   python /app/role_service.py
   ```

2. **ä»»åŠ¡åˆ›å»ºå’Œåˆ†é…**
   ```python
   # åˆ›å»ºéœ€æ±‚Issue
   issue_data = {
       'title': 'å®ç°ç”¨æˆ·ç™»å½•åŠŸèƒ½',
       'body': 'éœ€è¦å®ç°ç”¨æˆ·æ³¨å†Œã€ç™»å½•ã€å¯†ç é‡ç½®ç­‰åŠŸèƒ½',
       'labels': ['feature', 'high', 'backend'],
       'assignees': ['backend_ai_001']
   }
   
   github_client.create_issue('your-org/your-repo', **issue_data)
   ```

3. **è¿›åº¦è·Ÿè¸ª**
   ```python
   # æ›´æ–°IssueçŠ¶æ€
   github_client.update_issue(
       'your-org/your-repo', 
       issue_number=123, 
       state='open',
       labels=['in_progress']
   )
   ```

#### åç«¯å¼€å‘å·¥ä½œæµç¨‹
1. **æ¥æ”¶ä»»åŠ¡**
   ```bash
   # è¿›å…¥åç«¯å¼€å‘å®¹å™¨
   docker exec -it bee-swarm-backend-developer-1 bash
   
   # æ£€æŸ¥åˆ†é…çš„ä»»åŠ¡
   python /app/check_assigned_tasks.py
   ```

2. **ä»£ç å¼€å‘**
   ```python
   # ä½¿ç”¨AIå·¥å…·ç”Ÿæˆä»£ç 
   from ai_tools import AITools
   
   ai_tools = AITools()
   code = ai_tools.generate_code(
       'claude-code',
       'Create a JWT authentication system with login and register endpoints',
       context='Node.js, Express, MongoDB'
   )
   ```

3. **åˆ›å»ºPR**
   ```python
   # åˆ›å»ºåˆ†æ”¯
   github_client.create_branch('your-org/your-repo', 'feature/user-auth')
   
   # åˆ›å»ºPR
   pr_data = {
       'title': 'Add user authentication system',
       'body': 'Implements JWT-based authentication with login and register endpoints',
       'head': 'feature/user-auth',
       'base': 'main'
   }
   
   github_client.create_pull_request('your-org/your-repo', **pr_data)
   ```

#### å‰ç«¯å¼€å‘å·¥ä½œæµç¨‹
1. **APIå¯¹æ¥**
   ```python
   # è·å–APIæ–‡æ¡£
   api_docs = github_client.get_file_content(
       'your-org/your-repo', 
       'docs/api.md', 
       ref='feature/user-auth'
   )
   ```

2. **UIå¼€å‘**
   ```python
   # ä½¿ç”¨AIå·¥å…·ç”Ÿæˆå‰ç«¯ä»£ç 
   ui_code = ai_tools.generate_code(
       'warp',
       'Create a login form with React and Tailwind CSS',
       context=api_docs
   )
   ```

3. **é›†æˆæµ‹è¯•**
   ```python
   # è¿è¡Œå‰ç«¯æµ‹è¯•
   import subprocess
   subprocess.run(['npm', 'test'], cwd='/app/frontend')
   ```

#### QAå·¥ç¨‹å¸ˆå·¥ä½œæµç¨‹
1. **æµ‹è¯•è®¡åˆ’åˆ¶å®š**
   ```python
   # åˆ†æPRå˜æ›´
   pr = github_client.get_pull_request('your-org/your-repo', 456)
   changed_files = pr.get('changed_files', [])
   
   # ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
   test_cases = ai_tools.generate_code(
       'playwright',
       f'Generate test cases for files: {changed_files}',
       context=pr.get('body', '')
   )
   ```

2. **æ‰§è¡Œæµ‹è¯•**
   ```bash
   # è¿è¡Œè‡ªåŠ¨åŒ–æµ‹è¯•
   npx playwright test
   
   # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
   npx playwright show-report
   ```

3. **é—®é¢˜æŠ¥å‘Š**
   ```python
   # åˆ›å»ºé—®é¢˜Issue
   if test_failed:
       issue_data = {
           'title': f'Test failed: {test_name}',
           'body': f'Test {test_name} failed with error: {error_message}',
           'labels': ['bug', 'test'],
           'assignees': [pr_author]
       }
       github_client.create_issue('your-org/your-repo', **issue_data)
   ```

#### DevOpså·¥ç¨‹å¸ˆå·¥ä½œæµç¨‹
1. **éƒ¨ç½²å‡†å¤‡**
   ```python
   # æ£€æŸ¥PRçŠ¶æ€
   pr = github_client.get_pull_request('your-org/your-repo', 456)
   
   if pr.get('mergeable') and pr.get('review_approvals') >= 1:
       # åˆå¹¶PR
       github_client.merge_pull_request('your-org/your-repo', 456)
   ```

2. **è‡ªåŠ¨éƒ¨ç½²**
   ```bash
   # è§¦å‘CI/CDæµæ°´çº¿
   curl -X POST https://api.github.com/repos/your-org/your-repo/dispatches \
     -H "Authorization: token $GITHUB_TOKEN" \
     -d '{"event_type": "deploy", "client_payload": {"environment": "staging"}}'
   ```

3. **ç›‘æ§éƒ¨ç½²**
   ```python
   # æ£€æŸ¥éƒ¨ç½²çŠ¶æ€
   deployment_status = check_deployment_status('staging')
   
   if deployment_status['status'] == 'success':
       # å‘é€éƒ¨ç½²æˆåŠŸé€šçŸ¥
       communication_api.send_deployment_notification(
           'staging', 
           'v1.2.3', 
           'success',
           deployment_url='https://staging.example.com'
       )
   ```

## æŠ€æœ¯é¢ï¼šä»£ç å®ç°ç»†èŠ‚

### 5.1 AIå·¥å…·é›†æˆ

#### AIå·¥å…·ç®¡ç†å™¨
```python
# ai_tools.py
import subprocess
import json
import os
import time
from typing import Dict, Any, Optional
import logging

class AITools:
    def __init__(self):
        self.tools = {
            'gemini-cli': self._run_gemini_cli,
            'claude-code': self._run_claude_code,
            'rovo-dev': self._run_rovo_dev,
            'warp': self._run_warp,
            'cursor': self._run_cursor
        }
        
        self.logger = logging.getLogger(__name__)
        
        # å·¥å…·é…ç½®
        self.config = {
            'gemini-cli': {
                'timeout': 300,
                'max_retries': 3
            },
            'claude-code': {
                'timeout': 300,
                'max_retries': 3
            },
            'rovo-dev': {
                'timeout': 600,
                'max_retries': 2
            },
            'warp': {
                'timeout': 180,
                'max_retries': 3
            },
            'cursor': {
                'timeout': 180,
                'max_retries': 3
            }
        }
    
    def generate_code(self, tool: str, prompt: str, context: str = "", 
                     **kwargs) -> str:
        """ä½¿ç”¨æŒ‡å®šAIå·¥å…·ç”Ÿæˆä»£ç """
        if tool not in self.tools:
            raise ValueError(f"Unsupported tool: {tool}")
        
        self.logger.info(f"Generating code with {tool}")
        
        try:
            result = self.tools[tool](prompt, context, **kwargs)
            self.logger.info(f"Code generation successful with {tool}")
            return result
            
        except Exception as e:
            self.logger.error(f"Code generation failed with {tool}: {e}")
            raise
    
    def _run_gemini_cli(self, prompt: str, context: str = "", **kwargs) -> str:
        """è¿è¡ŒGemini CLI"""
        try:
            cmd = ['gemini', '--prompt', prompt]
            
            if context:
                cmd.extend(['--context', context])
            
            if kwargs.get('temperature'):
                cmd.extend(['--temperature', str(kwargs['temperature'])])
            
            if kwargs.get('max_tokens'):
                cmd.extend(['--max-tokens', str(kwargs['max_tokens'])])
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.config['gemini-cli']['timeout']
            )
            
            if result.returncode == 0:
                return result.stdout
            else:
                raise Exception(f"Gemini CLI error: {result.stderr}")
        
        except subprocess.TimeoutExpired:
            raise Exception("Gemini CLI timeout")
        except Exception as e:
            raise Exception(f"Gemini CLI failed: {e}")
    
    def _run_claude_code(self, prompt: str, code_context: str = "", **kwargs) -> str:
        """è¿è¡ŒClaude Code"""
        try:
            cmd = ['claude-code', '--prompt', prompt]
            
            if code_context:
                cmd.extend(['--code', code_context])
            
            if kwargs.get('model'):
                cmd.extend(['--model', kwargs['model']])
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.config['claude-code']['timeout']
            )
            
            if result.returncode == 0:
                return result.stdout
            else:
                raise Exception(f"Claude Code error: {result.stderr}")
        
        except subprocess.TimeoutExpired:
            raise Exception("Claude Code timeout")
        except Exception as e:
            raise Exception(f"Claude Code failed: {e}")
    
    def _run_rovo_dev(self, prompt: str, context: str = "", **kwargs) -> str:
        """è¿è¡ŒRovo Dev"""
        try:
            cmd = ['rovo-dev', 'generate', '--prompt', prompt]
            
            if context:
                cmd.extend(['--context', context])
            
            if kwargs.get('framework'):
                cmd.extend(['--framework', kwargs['framework']])
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.config['rovo-dev']['timeout']
            )
            
            if result.returncode == 0:
                return result.stdout
            else:
                raise Exception(f"Rovo Dev error: {result.stderr}")
        
        except subprocess.TimeoutExpired:
            raise Exception("Rovo Dev timeout")
        except Exception as e:
            raise Exception(f"Rovo Dev failed: {e}")
    
    def _run_warp(self, prompt: str, context: str = "", **kwargs) -> str:
        """è¿è¡ŒWarp"""
        try:
            # Warpé€šå¸¸é€šè¿‡APIè°ƒç”¨
            api_key = os.getenv('WARP_API_KEY')
            if not api_key:
                raise Exception("WARP_API_KEY not set")
            
            # è¿™é‡Œéœ€è¦æ ¹æ®Warpçš„å®é™…APIå®ç°
            # ç¤ºä¾‹å®ç°
            import requests
            
            response = requests.post(
                'https://api.warp.dev/v1/generate',
                headers={'Authorization': f'Bearer {api_key}'},
                json={
                    'prompt': prompt,
                    'context': context,
                    **kwargs
                },
                timeout=self.config['warp']['timeout']
            )
            
            if response.status_code == 200:
                return response.json()['code']
            else:
                raise Exception(f"Warp API error: {response.text}")
        
        except Exception as e:
            raise Exception(f"Warp failed: {e}")
    
    def _run_cursor(self, prompt: str, context: str = "", **kwargs) -> str:
        """è¿è¡ŒCursor"""
        try:
            # Cursoré€šå¸¸é€šè¿‡APIè°ƒç”¨
            api_key = os.getenv('CURSOR_API_KEY')
            if not api_key:
                raise Exception("CURSOR_API_KEY not set")
            
            # è¿™é‡Œéœ€è¦æ ¹æ®Cursorçš„å®é™…APIå®ç°
            # ç¤ºä¾‹å®ç°
            import requests
            
            response = requests.post(
                'https://api.cursor.sh/v1/generate',
                headers={'Authorization': f'Bearer {api_key}'},
                json={
                    'prompt': prompt,
                    'context': context,
                    **kwargs
                },
                timeout=self.config['cursor']['timeout']
            )
            
            if response.status_code == 200:
                return response.json()['code']
            else:
                raise Exception(f"Cursor API error: {response.text}")
        
        except Exception as e:
            raise Exception(f"Cursor failed: {e}")
    
    def review_code(self, tool: str, code: str, requirements: str = "") -> Dict[str, Any]:
        """ä½¿ç”¨AIå·¥å…·å®¡æŸ¥ä»£ç """
        prompt = f"""
        è¯·å®¡æŸ¥ä»¥ä¸‹ä»£ç ï¼Œå¹¶æä¾›æ”¹è¿›å»ºè®®ï¼š
        
        ä»£ç ï¼š
        {code}
        
        è¦æ±‚ï¼š
        {requirements}
        
        è¯·æä¾›ï¼š
        1. ä»£ç è´¨é‡è¯„åˆ†ï¼ˆ1-10ï¼‰
        2. å‘ç°çš„é—®é¢˜
        3. æ”¹è¿›å»ºè®®
        4. å®‰å…¨æ€§æ£€æŸ¥
        5. æ€§èƒ½ä¼˜åŒ–å»ºè®®
        """
        
        review_text = self.generate_code(tool, prompt)
        
        # è§£æå®¡æŸ¥ç»“æœ
        return self._parse_review_result(review_text)
    
    def _parse_review_result(self, review_text: str) -> Dict[str, Any]:
        """è§£æä»£ç å®¡æŸ¥ç»“æœ"""
        # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„è§£æé€»è¾‘
        # ç¤ºä¾‹å®ç°
        lines = review_text.split('\n')
        
        score = 8  # é»˜è®¤è¯„åˆ†
        issues = []
        suggestions = []
        security_concerns = []
        performance_suggestions = []
        
        for line in lines:
            line = line.strip()
            if 'è¯„åˆ†' in line or 'score' in line.lower():
                # æå–è¯„åˆ†
                import re
                score_match = re.search(r'(\d+)', line)
                if score_match:
                    score = int(score_match.group(1))
            
            elif 'é—®é¢˜' in line or 'issue' in line.lower():
                issues.append(line)
            
            elif 'å»ºè®®' in line or 'suggestion' in line.lower():
                suggestions.append(line)
            
            elif 'å®‰å…¨' in line or 'security' in line.lower():
                security_concerns.append(line)
            
            elif 'æ€§èƒ½' in line or 'performance' in line.lower():
                performance_suggestions.append(line)
        
        return {
            'score': score,
            'issues': issues,
            'suggestions': suggestions,
            'security_concerns': security_concerns,
            'performance_suggestions': performance_suggestions,
            'raw_text': review_text
        }
    
    def optimize_code(self, tool: str, code: str, optimization_type: str = "performance") -> str:
        """ä½¿ç”¨AIå·¥å…·ä¼˜åŒ–ä»£ç """
        prompt = f"""
        è¯·ä¼˜åŒ–ä»¥ä¸‹ä»£ç ï¼Œé‡ç‚¹ä¼˜åŒ–{optimization_type}ï¼š
        
        ä»£ç ï¼š
        {code}
        
        ä¼˜åŒ–è¦æ±‚ï¼š
        1. æé«˜{optimization_type}
        2. ä¿æŒä»£ç å¯è¯»æ€§
        3. ä¸æ”¹å˜åŠŸèƒ½é€»è¾‘
        4. æ·»åŠ å¿…è¦çš„æ³¨é‡Š
        """
        
        return self.generate_code(tool, prompt)
    
    def generate_tests(self, tool: str, code: str, test_framework: str = "jest") -> str:
        """ä½¿ç”¨AIå·¥å…·ç”Ÿæˆæµ‹è¯•ä»£ç """
        prompt = f"""
        è¯·ä¸ºä»¥ä¸‹ä»£ç ç”Ÿæˆ{test_framework}æµ‹è¯•ç”¨ä¾‹ï¼š
        
        ä»£ç ï¼š
        {code}
        
        æµ‹è¯•è¦æ±‚ï¼š
        1. è¦†ç›–æ‰€æœ‰ä¸»è¦åŠŸèƒ½
        2. åŒ…å«è¾¹ç•Œæ¡ä»¶æµ‹è¯•
        3. åŒ…å«é”™è¯¯æƒ…å†µæµ‹è¯•
        4. æµ‹è¯•ç”¨ä¾‹å‘½åæ¸…æ™°
        5. ä½¿ç”¨{test_framework}è¯­æ³•
        """
        
        return self.generate_code(tool, prompt)
```

### 5.2 ç›‘æ§å’Œæ—¥å¿—

#### ç›‘æ§ç³»ç»Ÿ
```python
# monitoring.py
import logging
import time
import psutil
import requests
import json
from datetime import datetime, timedelta
from typing import Dict, Any, List
import threading

class Monitoring:
    def __init__(self, role_name: str):
        self.role_name = role_name
        self.logger = logging.getLogger(f"monitoring.{role_name}")
        
        # è®¾ç½®æ—¥å¿—æ ¼å¼
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        
        # æ–‡ä»¶å¤„ç†å™¨
        file_handler = logging.FileHandler(f'/app/logs/{role_name}.log')
        file_handler.setFormatter(formatter)
        self.logger.addHandler(file_handler)
        
        # æ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)
        self.logger.addHandler(console_handler)
        
        self.logger.setLevel(logging.INFO)
        
        # æ€§èƒ½æŒ‡æ ‡
        self.performance_history = []
        self.error_history = []
        self.activity_history = []
        
        # å‘Šè­¦é˜ˆå€¼
        self.alert_thresholds = {
            'cpu_percent': 80,
            'memory_percent': 85,
            'disk_percent': 90,
            'error_rate': 0.1
        }
        
        # å¯åŠ¨ç›‘æ§çº¿ç¨‹
        self.monitoring_thread = threading.Thread(target=self._monitoring_loop)
        self.monitoring_thread.daemon = True
        self.monitoring_thread.start()
    
    def log_activity(self, action: str, details: Dict[str, Any] = None):
        """è®°å½•è§’è‰²æ´»åŠ¨"""
        log_data = {
            'timestamp': datetime.now().isoformat(),
            'role': self.role_name,
            'action': action,
            'details': details or {}
        }
        
        self.logger.info(f"Activity: {action} - {details}")
        self.activity_history.append(log_data)
        
        # å‘é€åˆ°ç›‘æ§ç³»ç»Ÿ
        self._send_to_monitoring(log_data)
    
    def track_performance(self) -> Dict[str, Any]:
        """è·Ÿè¸ªæ€§èƒ½æŒ‡æ ‡"""
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        metrics = {
            'timestamp': datetime.now().isoformat(),
            'role': self.role_name,
            'cpu_percent': cpu_percent,
            'memory_percent': memory.percent,
            'disk_percent': disk.percent,
            'memory_available': memory.available,
            'disk_free': disk.free,
            'load_average': psutil.getloadavg()
        }
        
        self.logger.info(f"Performance metrics: {metrics}")
        self.performance_history.append(metrics)
        
        # æ£€æŸ¥å‘Šè­¦é˜ˆå€¼
        self._check_alert_thresholds(metrics)
        
        return metrics
    
    def alert_on_issues(self, issue_type: str, details: str):
        """é—®é¢˜å‘Šè­¦"""
        alert_data = {
            'timestamp': datetime.now().isoformat(),
            'role': self.role_name,
            'issue_type': issue_type,
            'details': details,
            'severity': 'warning'
        }
        
        self.logger.warning(f"Alert: {issue_type} - {details}")
        self.error_history.append(alert_data)
        
        # å‘é€å‘Šè­¦é€šçŸ¥
        self._send_alert(alert_data)
    
    def track_api_calls(self, api_name: str, response_time: float, 
                       status_code: int, success: bool):
        """è·Ÿè¸ªAPIè°ƒç”¨"""
        api_data = {
            'timestamp': datetime.now().isoformat(),
            'role': self.role_name,
            'api_name': api_name,
            'response_time': response_time,
            'status_code': status_code,
            'success': success
        }
        
        self.logger.info(f"API call: {api_name} - {response_time}ms - {status_code}")
        
        # æ£€æŸ¥APIæ€§èƒ½
        if response_time > 5000:  # 5ç§’
            self.alert_on_issues('slow_api_call', f"{api_name} took {response_time}ms")
        
        if not success:
            self.alert_on_issues('api_error', f"{api_name} failed with {status_code}")
    
    def track_github_operations(self, operation: str, success: bool, 
                               details: Dict[str, Any] = None):
        """è·Ÿè¸ªGitHubæ“ä½œ"""
        github_data = {
            'timestamp': datetime.now().isoformat(),
            'role': self.role_name,
            'operation': operation,
            'success': success,
            'details': details or {}
        }
        
        self.logger.info(f"GitHub operation: {operation} - {'success' if success else 'failed'}")
        
        if not success:
            self.alert_on_issues('github_operation_failed', f"{operation} failed")
    
    def get_performance_summary(self, hours: int = 24) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æ‘˜è¦"""
        cutoff_time = datetime.now() - timedelta(hours=hours)
        
        recent_metrics = [
            m for m in self.performance_history 
            if datetime.fromisoformat(m['timestamp']) > cutoff_time
        ]
        
        if not recent_metrics:
            return {}
        
        # è®¡ç®—å¹³å‡å€¼
        avg_cpu = sum(m['cpu_percent'] for m in recent_metrics) / len(recent_metrics)
        avg_memory = sum(m['memory_percent'] for m in recent_metrics) / len(recent_metrics)
        avg_disk = sum(m['disk_percent'] for m in recent_metrics) / len(recent_metrics)
        
        # è®¡ç®—æœ€å¤§å€¼
        max_cpu = max(m['cpu_percent'] for m in recent_metrics)
        max_memory = max(m['memory_percent'] for m in recent_metrics)
        max_disk = max(m['disk_percent'] for m in recent_metrics)
        
        return {
            'period_hours': hours,
            'avg_cpu_percent': round(avg_cpu, 2),
            'avg_memory_percent': round(avg_memory, 2),
            'avg_disk_percent': round(avg_disk, 2),
            'max_cpu_percent': max_cpu,
            'max_memory_percent': max_memory,
            'max_disk_percent': max_disk,
            'total_metrics': len(recent_metrics)
        }
    
    def get_error_summary(self, hours: int = 24) -> Dict[str, Any]:
        """è·å–é”™è¯¯æ‘˜è¦"""
        cutoff_time = datetime.now() - timedelta(hours=hours)
        
        recent_errors = [
            e for e in self.error_history 
            if datetime.fromisoformat(e['timestamp']) > cutoff_time
        ]
        
        error_types = {}
        for error in recent_errors:
            error_type = error['issue_type']
            error_types[error_type] = error_types.get(error_type, 0) + 1
        
        return {
            'period_hours': hours,
            'total_errors': len(recent_errors),
            'error_types': error_types,
            'recent_errors': recent_errors[-10:]  # æœ€è¿‘10ä¸ªé”™è¯¯
        }
    
    def _check_alert_thresholds(self, metrics: Dict[str, Any]):
        """æ£€æŸ¥å‘Šè­¦é˜ˆå€¼"""
        if metrics['cpu_percent'] > self.alert_thresholds['cpu_percent']:
            self.alert_on_issues('high_cpu_usage', f"CPU usage: {metrics['cpu_percent']}%")
        
        if metrics['memory_percent'] > self.alert_thresholds['memory_percent']:
            self.alert_on_issues('high_memory_usage', f"Memory usage: {metrics['memory_percent']}%")
        
        if metrics['disk_percent'] > self.alert_thresholds['disk_percent']:
            self.alert_on_issues('high_disk_usage', f"Disk usage: {metrics['disk_percent']}%")
    
    def _monitoring_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while True:
            try:
                # è·Ÿè¸ªæ€§èƒ½
                self.track_performance()
                
                # æ¸…ç†å†å²æ•°æ®ï¼ˆä¿ç•™æœ€è¿‘7å¤©ï¼‰
                self._cleanup_history()
                
                # ç­‰å¾…ä¸‹æ¬¡æ£€æŸ¥
                time.sleep(300)  # 5åˆ†é’Ÿ
                
            except Exception as e:
                self.logger.error(f"Error in monitoring loop: {e}")
                time.sleep(60)
    
    def _cleanup_history(self):
        """æ¸…ç†å†å²æ•°æ®"""
        cutoff_time = datetime.now() - timedelta(days=7)
        
        # æ¸…ç†æ€§èƒ½å†å²
        self.performance_history = [
            m for m in self.performance_history 
            if datetime.fromisoformat(m['timestamp']) > cutoff_time
        ]
        
        # æ¸…ç†é”™è¯¯å†å²
        self.error_history = [
            e for e in self.error_history 
            if datetime.fromisoformat(e['timestamp']) > cutoff_time
        ]
        
        # æ¸…ç†æ´»åŠ¨å†å²
        self.activity_history = [
            a for a in self.activity_history 
            if datetime.fromisoformat(a['timestamp']) > cutoff_time
        ]
    
    def _send_to_monitoring(self, data: Dict[str, Any]):
        """å‘é€æ•°æ®åˆ°ç›‘æ§ç³»ç»Ÿ"""
        try:
            # è¿™é‡Œå¯ä»¥é›†æˆPrometheusã€Grafanaç­‰ç›‘æ§ç³»ç»Ÿ
            # ç¤ºä¾‹ï¼šå‘é€åˆ°Prometheus
            prometheus_url = os.getenv('PROMETHEUS_URL')
            if prometheus_url:
                requests.post(f"{prometheus_url}/metrics", json=data, timeout=5)
        except Exception as e:
            self.logger.error(f"Failed to send to monitoring: {e}")
    
    def _send_alert(self, alert_data: Dict[str, Any]):
        """å‘é€å‘Šè­¦é€šçŸ¥"""
        try:
            # è¿™é‡Œå¯ä»¥é›†æˆSlackã€é‚®ä»¶ç­‰é€šçŸ¥ç³»ç»Ÿ
            # ç¤ºä¾‹ï¼šå‘é€åˆ°Slack
            slack_webhook = os.getenv('SLACK_WEBHOOK_URL')
            if slack_webhook:
                slack_message = {
                    'text': f"ğŸš¨ Alert from {self.role_name}: {alert_data['issue_type']}",
                    'attachments': [{
                        'text': alert_data['details'],
                        'color': 'danger'
                    }]
                }
                requests.post(slack_webhook, json=slack_message, timeout=5)
        except Exception as e:
            self.logger.error(f"Failed to send alert: {e}")
```

### 5.3 éƒ¨ç½²è„šæœ¬

#### è‡ªåŠ¨åŒ–éƒ¨ç½²è„šæœ¬
```bash
#!/bin/bash
# scripts/deploy.sh

set -e

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

log_warn() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# æ£€æŸ¥ç¯å¢ƒ
check_environment() {
    log_info "Checking environment..."
    
    # æ£€æŸ¥Docker
    if ! command -v docker &> /dev/null; then
        log_error "Docker is not installed"
        exit 1
    fi
    
    # æ£€æŸ¥Docker Compose
    if ! command -v docker-compose &> /dev/null; then
        log_error "Docker Compose is not installed"
        exit 1
    fi
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡æ–‡ä»¶
    if [ ! -f .env ]; then
        log_error ".env file not found"
        exit 1
    fi
    
    log_info "Environment check passed"
}

# æ„å»ºé•œåƒ
build_images() {
    log_info "Building Docker images..."
    
    # æ„å»ºåŸºç¡€é•œåƒ
    log_info "Building base images..."
    cd novnc_base
    docker build -t vnc-base . || {
        log_error "Failed to build vnc-base image"
        exit 1
    }
    cd ..
    
    cd novnc_llm_cli
    docker build -t vnc-llm-cli . || {
        log_error "Failed to build vnc-llm-cli image"
        exit 1
    }
    cd ..
    
    # æ„å»ºè§’è‰²é•œåƒ
    log_info "Building role images..."
    docker-compose build || {
        log_error "Failed to build role images"
        exit 1
    }
    
    log_info "Image build completed"
}

# å¯åŠ¨æœåŠ¡
start_services() {
    log_info "Starting services..."
    
    # å¯åŠ¨æ‰€æœ‰æœåŠ¡
    docker-compose up -d || {
        log_error "Failed to start services"
        exit 1
    }
    
    # ç­‰å¾…æœåŠ¡å¯åŠ¨
    log_info "Waiting for services to start..."
    sleep 30
    
    # æ£€æŸ¥æœåŠ¡çŠ¶æ€
    check_service_status
    
    log_info "Services started successfully"
}

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
check_service_status() {
    log_info "Checking service status..."
    
    services=("product-manager" "backend-developer" "frontend-developer" "qa-engineer" "devops-engineer")
    
    for service in "${services[@]}"; do
        if docker-compose ps | grep -q "$service.*Up"; then
            log_info "$service is running"
        else
            log_error "$service is not running"
            docker-compose logs "$service"
        fi
    done
}

# é…ç½®GitHub Webhook
setup_webhook() {
    log_info "Setting up GitHub webhook..."
    
    # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…æƒ…å†µé…ç½®
    # å¯ä»¥ä½¿ç”¨GitHub APIè‡ªåŠ¨é…ç½®webhook
    
    log_warn "Please manually configure GitHub webhook:"
    log_warn "URL: https://your-domain.com/webhook"
    log_warn "Content type: application/json"
    log_warn "Secret: your-webhook-secret"
    log_warn "Events: Issues, Pull requests, Push"
}

# å¥åº·æ£€æŸ¥
health_check() {
    log_info "Performing health check..."
    
    # æ£€æŸ¥å®¹å™¨å¥åº·çŠ¶æ€
    unhealthy_containers=$(docker-compose ps | grep "unhealthy" | wc -l)
    
    if [ "$unhealthy_containers" -gt 0 ]; then
        log_error "Found $unhealthy_containers unhealthy containers"
        docker-compose ps
        exit 1
    fi
    
    # æ£€æŸ¥ç«¯å£ç›‘å¬
    ports=(6080 6081 6082 6083 6084)
    for port in "${ports[@]}"; do
        if netstat -tuln | grep -q ":$port "; then
            log_info "Port $port is listening"
        else
            log_warn "Port $port is not listening"
        fi
    done
    
    log_info "Health check completed"
}

# æ¸…ç†æ—§å®¹å™¨
cleanup_old_containers() {
    log_info "Cleaning up old containers..."
    
    # åœæ­¢å¹¶åˆ é™¤æ—§å®¹å™¨
    docker-compose down --remove-orphans || true
    
    # æ¸…ç†æœªä½¿ç”¨çš„é•œåƒ
    docker image prune -f || true
    
    log_info "Cleanup completed"
}

# å¤‡ä»½æ•°æ®
backup_data() {
    log_info "Backing up data..."
    
    backup_dir="backups/$(date +%Y%m%d_%H%M%S)"
    mkdir -p "$backup_dir"
    
    # å¤‡ä»½é…ç½®æ–‡ä»¶
    cp .env "$backup_dir/"
    cp docker-compose.yml "$backup_dir/"
    
    # å¤‡ä»½æ—¥å¿—
    if [ -d "logs" ]; then
        cp -r logs "$backup_dir/"
    fi
    
    log_info "Backup saved to $backup_dir"
}

# ä¸»å‡½æ•°
main() {
    log_info "Starting Bee Swarm deployment..."
    
    # æ£€æŸ¥ç¯å¢ƒ
    check_environment
    
    # å¤‡ä»½æ•°æ®
    backup_data
    
    # æ¸…ç†æ—§å®¹å™¨
    cleanup_old_containers
    
    # æ„å»ºé•œåƒ
    build_images
    
    # å¯åŠ¨æœåŠ¡
    start_services
    
    # å¥åº·æ£€æŸ¥
    health_check
    
    # é…ç½®webhook
    setup_webhook
    
    log_info "Deployment completed successfully!"
    log_info "Access URLs:"
    log_info "  Product Manager: http://localhost:6080"
    log_info "  Backend Developer: http://localhost:6081"
    log_info "  Frontend Developer: http://localhost:6082"
    log_info "  QA Engineer: http://localhost:6083"
    log_info "  DevOps Engineer: http://localhost:6084"
}

# è¿è¡Œä¸»å‡½æ•°
main "$@"
```

#### ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²è„šæœ¬
```bash
#!/bin/bash
# scripts/deploy-prod.sh

set -e

# ç”Ÿäº§ç¯å¢ƒé…ç½®
ENVIRONMENT="production"
VPS_COUNT=20
REGION="us-west-2"

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m'

log_info() {
    echo -e "${GREEN}[INFO]${NC} $1"
}

log_warn() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# éƒ¨ç½²åˆ°VPSé›†ç¾¤
deploy_to_vps_cluster() {
    log_info "Deploying to VPS cluster..."
    
    for i in $(seq 1 $VPS_COUNT); do
        vps_name="vps-$i"
        log_info "Deploying to $vps_name..."
        
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„VPSç®¡ç†æ–¹å¼å®ç°
        # ç¤ºä¾‹ï¼šä½¿ç”¨SSHéƒ¨ç½²
        ssh "user@$vps_name" << 'EOF'
            cd /opt/bee-swarm
            git pull origin main
            docker-compose down
            docker-compose pull
            docker-compose up -d
            docker system prune -f
EOF
        
        log_info "$vps_name deployment completed"
    done
}

# é…ç½®è´Ÿè½½å‡è¡¡
setup_load_balancer() {
    log_info "Setting up load balancer..."
    
    # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„è´Ÿè½½å‡è¡¡å™¨å®ç°
    # ç¤ºä¾‹ï¼šä½¿ç”¨Nginxé…ç½®
    
    cat > /etc/nginx/sites-available/bee-swarm << 'EOF'
upstream bee_swarm_backend {
    server vps-1:6080;
    server vps-2:6081;
    server vps-3:6082;
    server vps-4:6083;
    server vps-5:6084;
    # ... æ›´å¤šVPS
}

server {
    listen 80;
    server_name bee-swarm.example.com;
    
    location / {
        proxy_pass http://bee_swarm_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
EOF
    
    ln -sf /etc/nginx/sites-available/bee-swarm /etc/nginx/sites-enabled/
    nginx -t && systemctl reload nginx
    
    log_info "Load balancer configured"
}

# é…ç½®ç›‘æ§
setup_monitoring() {
    log_info "Setting up monitoring..."
    
    # éƒ¨ç½²Prometheus
    docker run -d \
        --name prometheus \
        -p 9090:9090 \
        -v /opt/prometheus.yml:/etc/prometheus/prometheus.yml \
        prom/prometheus
    
    # éƒ¨ç½²Grafana
    docker run -d \
        --name grafana \
        -p 3000:3000 \
        -e GF_SECURITY_ADMIN_PASSWORD=admin \
        grafana/grafana
    
    log_info "Monitoring setup completed"
}

# é…ç½®å¤‡ä»½
setup_backup() {
    log_info "Setting up backup..."
    
    # åˆ›å»ºå¤‡ä»½è„šæœ¬
    cat > /opt/backup-bee-swarm.sh << 'EOF'
#!/bin/bash
BACKUP_DIR="/backup/bee-swarm/$(date +%Y%m%d_%H%M%S)"
mkdir -p "$BACKUP_DIR"

# å¤‡ä»½æ•°æ®å·
docker run --rm -v bee-swarm_pm_data:/data -v "$BACKUP_DIR":/backup alpine tar czf /backup/pm_data.tar.gz -C /data .
docker run --rm -v bee-swarm_backend_data:/data -v "$BACKUP_DIR":/backup alpine tar czf /backup/backend_data.tar.gz -C /data .
# ... æ›´å¤šæ•°æ®å·

# æ¸…ç†æ—§å¤‡ä»½ï¼ˆä¿ç•™7å¤©ï¼‰
find /backup/bee-swarm -type d -mtime +7 -exec rm -rf {} \;
EOF
    
    chmod +x /opt/backup-bee-swarm.sh
    
    # æ·»åŠ åˆ°crontab
    echo "0 2 * * * /opt/backup-bee-swarm.sh" | crontab -
    
    log_info "Backup setup completed"
}

# ä¸»å‡½æ•°
main() {
    log_info "Starting production deployment..."
    
    # éƒ¨ç½²åˆ°VPSé›†ç¾¤
    deploy_to_vps_cluster
    
    # é…ç½®è´Ÿè½½å‡è¡¡
    setup_load_balancer
    
    # é…ç½®ç›‘æ§
    setup_monitoring
    
    # é…ç½®å¤‡ä»½
    setup_backup
    
    log_info "Production deployment completed!"
}

main "$@"
``` 